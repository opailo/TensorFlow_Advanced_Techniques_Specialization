{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Class_Activation_Maps_With_Fashion_MNIST.ipynb","provenance":[],"authorship_tag":"ABX9TyMr97W3uE/KKBYOjzmPv/tC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Class Activation Maps with Fashion MNIST\n","\n","Implement a simple class activation map (CAM) of a model trained on the Fashion MNIST dataset\n","* The CAM will show what parts of the image the model was paying attention to when deciding the class of the image "],"metadata":{"id":"QV02yOq3lcER"}},{"cell_type":"code","source":["##Imports \n","\n","import keras\n","from keras.datasets import fashion_mnist\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential, Model \n","from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n","import scipy as sp"],"metadata":{"id":"ysFXTQ1zl5lq","executionInfo":{"status":"ok","timestamp":1657297000948,"user_tz":420,"elapsed":3026,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["##Download and Prep the Data"],"metadata":{"id":"m9sAz7jymRle"}},{"cell_type":"code","source":["#Load the Fashion MNIST Dataset\n","(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUrkACK0mX9d","executionInfo":{"status":"ok","timestamp":1657297061417,"user_tz":420,"elapsed":1750,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"7b1c351c-2b52-4acc-f119-ca92dc12bd7f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 1us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["len(X_train), len(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aZ9YlDC6mlA1","executionInfo":{"status":"ok","timestamp":1657297159338,"user_tz":420,"elapsed":5,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"97d7dac4-13c8-4399-956c-3305beb27c84"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 10000)"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Put an additional axis for the channels of the image\n","\n","Fashion MNIST is grayscale so palce a `1` at the end (other datasets would need `3` of they are RGB)"],"metadata":{"id":"LzYfU8Ijm8hF"}},{"cell_type":"code","source":["X_train = X_train.reshape(len(X_train), 28, 28, 1)\n","X_test = X_test.reshape(len(X_test), 28, 28, 1)"],"metadata":{"id":"9bzhJRIbnCc2","executionInfo":{"status":"ok","timestamp":1657297306092,"user_tz":420,"elapsed":154,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Normalize the pizel values from 0 to 1"],"metadata":{"id":"7MNRQNGYngZT"}},{"cell_type":"code","source":["X_train = X_train / 255\n","X_test = X_test / 255\n","\n","#Cast to float\n","X_train = X_train.astype('float')\n","X_test = X_test.astype('float')"],"metadata":{"id":"pWQxrjpnnnP1","executionInfo":{"status":"ok","timestamp":1657297418165,"user_tz":420,"elapsed":500,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["##Utilities"],"metadata":{"id":"W-v_DUHan7qF"}},{"cell_type":"code","source":["def show_img(img):\n","  \"\"\"\n","  Reshapes and displays an image \n","  \"\"\"\n","\n","  #Convert to float array if img is not yet preprocessed \n","  img = np.array(img, dtype='float')\n","\n","  #Remove channel dimensions \n","  img = img.reshape((28,28))\n","\n","  #Display image\n","  plt.imshow(img)"],"metadata":{"id":"hp2d2SSLns0V","executionInfo":{"status":"ok","timestamp":1657298024139,"user_tz":420,"elapsed":141,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#Function test\n","show_img(X_train[5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"2jLGXG_Mp4uS","executionInfo":{"status":"ok","timestamp":1657298026759,"user_tz":420,"elapsed":325,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"e03737e3-32d5-4458-fb94-cf72735314de"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["##Build the Classifier "],"metadata":{"id":"Xnbjpwb3qjpp"}},{"cell_type":"markdown","source":["##Define the Model \n","\n","The image will go through four convolutions each followed by a pooling layer\n","\n","The final Dense layer will output the probabilities for each class"],"metadata":{"id":"Q4ty6n_zqoMV"}},{"cell_type":"code","source":["#Use the Sequential API to make things easier \n","model = Sequential()\n","\n","#Notice that the padding parameter to recover the lost border pixels when doing the convolution \n","model.add(Conv2D(16, input_shape=(28,28,1), kernel_size=(3,3), activation='relu', padding='same'))\n","#Pooling layer with a stride of 2 will reduce the image dimensions by half \n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","#Pass through three more convolutions / poolings with each increasing the filters \n","model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","#Last convolution doesn't have MaxPooling\n","model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\n","\n","#Use GlobalAveragePooling to take into account lesser intensity pixels \n","model.add(GlobalAveragePooling2D())\n","\n","#Ouput the class probabilities \n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8bLRpuIq2vR","executionInfo":{"status":"ok","timestamp":1657298620029,"user_tz":420,"elapsed":707,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"29bb008a-51c9-498b-9179-cc3dc2d9af1a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 28, 28, 16)        160       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 14, 14, 32)        4640      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 7, 7, 64)          18496     \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 3, 3, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 3, 3, 128)         73856     \n","                                                                 \n"," global_average_pooling2d (G  (None, 128)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 98,442\n","Trainable params: 98,442\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["##Train the Model \n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","#Train the model \n","model.fit(X_train, Y_train,\n","          batch_size=32,\n","          epochs=5,\n","          validation_split=0.1,\n","          shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOy8GdM8sinG","executionInfo":{"status":"ok","timestamp":1657299120619,"user_tz":420,"elapsed":382995,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"abc4d307-b6d5-46cf-82c8-6342b594aa3f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1688/1688 [==============================] - 67s 39ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.0925\n","Epoch 2/5\n","1688/1688 [==============================] - 74s 44ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3030 - val_accuracy: 0.0942\n","Epoch 3/5\n","1688/1688 [==============================] - 77s 46ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3029 - val_accuracy: 0.0942\n","Epoch 4/5\n","1688/1688 [==============================] - 68s 40ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3031 - val_accuracy: 0.0925\n","Epoch 5/5\n","1688/1688 [==============================] - 59s 35ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3031 - val_accuracy: 0.0985\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc2d4845610>"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["##Generate the CAM\n","\n","To generate the class activation map, get the features detected in the last convolution layer and see which ones are most active when generating the output probabilities"],"metadata":{"id":"OlLhFh-5s-g8"}},{"cell_type":"code","source":["#First convolution layer \n","print(model.layers[-3].name)\n","\n","#Global average pooling layer\n","print(model.layers[-2].name)\n","\n","#Output of the classifier \n","print(model.layers[-1].name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"suFZ63WMtLpW","executionInfo":{"status":"ok","timestamp":1657299121098,"user_tz":420,"elapsed":4,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"c73e44b9-3364-4ad5-8990-440aa5cf0267"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["conv2d_3\n","global_average_pooling2d\n","dense\n"]}]},{"cell_type":"markdown","source":["Create the CAM model "],"metadata":{"id":"4eqpxIqjtieF"}},{"cell_type":"code","source":["#Same as previous model but with an additional output \n","cam_model = Model(inputs=model.input, outputs=[model.layers[-3].output,\n","                                               model.layers[-1].output])"],"metadata":{"id":"mfUnmUtLtlFB","executionInfo":{"status":"ok","timestamp":1657299121098,"user_tz":420,"elapsed":2,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Use the CAM model to predict on the test set so that it generates the features and the predicted probability for each class (`results`)"],"metadata":{"id":"Dy5wfm7-t8ds"}},{"cell_type":"code","source":["#get the features and results of the test images using the newly created model \n","features, results = cam_model.predict(X_test)\n","\n","#Shape of features \n","print('features shape: ', features.shape, '\\n\\nResults shape: ', results.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JAukZvdvFig","executionInfo":{"status":"ok","timestamp":1657299414247,"user_tz":420,"elapsed":3477,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"e706b4b4-a00f-42b4-b350-288c31fe6809"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["features shape:  (10000, 3, 3, 128) \n","\n","Results shape:  (10000, 10)\n"]}]},{"cell_type":"markdown","source":["Generate the CAM by getting the dot product of the class activation features and the class activation weights \n","\n","Use the weights from the GlobalAveragePooling layer to calculate the activations of each feature given a particular class\n","\n","* Get the weights from the dense layer that follows the GAP layer  * The last conv2D layer has (h,w,depth) of (3 x 3 x 128), so there are 128 features.\n"," * The global average pooling layer collapses the h,w,f (3 x 3 x 128) into a dense layer of 128 neurons (1 neuron per feature).\n"," * The activations from the global average pooling layer get passed to the last dense layer.\n"," * The last dense layer assigns weights to each of those 128 features (for each of the 10 classes),\n"," * So the weights of the last dense layer (which immmediately follows the global average pooling layer) are referred to in this context as the \"weights of the global average pooling layer\"."],"metadata":{"id":"4C6vK4wsveeP"}},{"cell_type":"markdown","source":["For each of the 10 classes, there are 128 features each with their own feature weight"],"metadata":{"id":"1nDSbPlWwbJf"}},{"cell_type":"code","source":["#These are the weights going into the softmax layer \n","last_dense_layer = model.layers[-1]\n","\n","#Get the weights list. Index 0 contains the weights, Index 1 contains the biases\n","gap_weights_list = last_dense_layer.get_weights()\n","\n","print('gap_weights_list index 0 contains the weights ', gap_weights_list[0].shape)\n","print('gap_weights_list index 1 contains the biases ', gap_weights_list[1].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBzRQ_TZwjtv","executionInfo":{"status":"ok","timestamp":1657300242080,"user_tz":420,"elapsed":132,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"9ae101b4-3059-42a6-d8e1-96839feab52c"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["gap_weights_list index 0 contains the weights  (128, 10)\n","gap_weights_list index 1 contains the biases  (10,)\n"]}]},{"cell_type":"code","source":["#Show the number of features per class and the total number of classes \n","gap_weights = gap_weights_list[0]\n","\n","print(f'There are {gap_weights.shape[0]} feature weights and {gap_weights.shape[1]} classes')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUXS-KCzytcn","executionInfo":{"status":"ok","timestamp":1657300330345,"user_tz":420,"elapsed":121,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"5974b4e9-43fb-4c61-f7a6-d209229a0337"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 128 feature weights and 10 classes\n"]}]},{"cell_type":"markdown","source":["Get the features for a specific image (indexed between 0 and 999)"],"metadata":{"id":"Eipl_Q7QzG5_"}},{"cell_type":"code","source":["idx = 883\n","features_for_img = features[idx, :, :, :]\n","\n","print(f'the features for img index {idx} has shape (height, width, num of features channels): ', features_for_img.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OypCDPSh1W1-","executionInfo":{"status":"ok","timestamp":1657301037348,"user_tz":420,"elapsed":125,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"e10fda82-1c2d-4d35-8a67-f08e2bbf6a7c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["the features for img index 883 has shape (height, width, num of features channels):  (3, 3, 128)\n"]}]},{"cell_type":"markdown","source":["The features have a height and width of 3x3. Scale them up to the original image height and width of 28x28"],"metadata":{"id":"3ObEjLC41vri"}},{"cell_type":"code","source":["features_for_img_scaled = sp.ndimage.zoom(features_for_img, (28/3, 28/3, 1), order=2)\n","\n","#Check the shape after scaling back to 28x28\n","print(features_for_img_scaled.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JfAT2Sx18gI","executionInfo":{"status":"ok","timestamp":1657301181413,"user_tz":420,"elapsed":118,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"1f1ec14c-bc3e-43d9-ca7f-550178d3b7f7"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["(28, 28, 128)\n"]}]},{"cell_type":"markdown","source":["For a particular class (0 to 9) get the 128 feature weights \n","* Take the dot product with the scaled features for the selected image with the weights \n","* The shapes are scaled features: (h, w, depth) of (28x28x128)\n","* The dot product produces the class activation map witht he shape equal to the height and width of the image: 28x28"],"metadata":{"id":"U6IQ2Bpb2S3X"}},{"cell_type":"code","source":["#Select the weights that are used for a specific class\n","class_id = 6\n","\n","#Take the dot product between the sclaed image features and the weights for it \n","gap_weight_for_one_class = gap_weights[:, class_id]\n","\n","print('features_for_img_scaled has shape: ', features_for_img_scaled.shape)\n","print('gap_weights_for_one_class has shape: ', gap_weight_for_one_class.shape)\n","\n","#Take the dot product between the scaled features and the weights for one class \n","cam = np.dot(features_for_img_scaled, gap_weight_for_one_class)\n","print('\\nclass activation map shape: ', cam.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Kcnb-PG2wMe","executionInfo":{"status":"ok","timestamp":1657301549901,"user_tz":420,"elapsed":110,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"acfa8646-f30b-4935-bf2e-c16fd3fb52c9"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["features_for_img_scaled has shape:  (28, 28, 128)\n","gap_weights_for_one_class has shape:  (128,)\n","\n","class activation map shape:  (28, 28)\n"]}]},{"cell_type":"markdown","source":["##Conceptual Interpretation \n","\n","* In the 28 x 28 x 128 feature map, each of the 128 feature filters is tailored to look for a specific set of features (for example, a shoelace).\n"," * The actual features are learned, not selected by you directly.\n","* Each of the 128 weights for a particular class decide how much weight to give to each of the 128 features, for that class.\n"," * For instance, for the \"shoe\" class, it may have a higher weight for the feature filters that look for shoelaces.\n","* At each of the 28 by 28 pixels, you can take the vector of 128 features and compare them with the vector of 128 weights.\n"," * You can do this comparison with a dot product.\n","The dot product results in a scalar value at each pixel.\n"," * Apply this dot product across all of the 28 x 28 pixels.\n"," * The scalar result of the dot product will be larger when the image both has the particular feature (e.g. shoelace), and that feature is also weighted more heavily for the particular class (e.g shoe)."],"metadata":{"id":"S1aFcZYS6Dju"}},{"cell_type":"markdown","source":["So you've created a matrix with the same number of pixels as the image but each value at each pixel is higher when that pixel is relevant to the prediction of a particular class"],"metadata":{"id":"M5ft12ML6vru"}},{"cell_type":"code","source":["def show_cam(image_index):\n","  \"\"\"Display the class activation map of a particular image\"\"\"\n","\n","  # takes the features of the chosen image\n","  features_for_img = features[image_index, :, :, :]\n","\n","  # get the class with the highest output probability\n","  prediction = np.argmax(results[image_index])\n","\n","  # get the gap weights and the predicted class (shape 3x3)\n","  class_activation_weights = gap_weights[:, prediction]\n","\n","  # upsample the features to the image's original shape (28, 28)\n","  class_activation_features = sp.ndimage.zoom(features_for_img, (28/3, 28/3, 1), order=2)\n","\n","  # compute the intesity of each feature in the CAM\n","  cam_output = np.dot(class_activation_features, class_activation_weights)\n","\n","  print(\"Predicted class = \"+ str(prediction) + \", Probabilty = \" + str(results[image_index][prediction]))\n","\n","  # show the upsampled image\n","  plt.imshow(np.squeeze(X_test[image_index], -1), alpha=0.5)\n","\n","  # strongly classified (95% probability) images will be in green, else red\n","  if results[image_index][prediction]>0.95:\n","    cmap_str = \"Greens\"\n","  else:\n","    cmap_str = \"Reds\"\n","\n","  # over the cam output\n","  plt.imshow(cam_output, cmap=cmap_str, alpha=0.5)\n","\n","  # display the image\n","  plt.show()"],"metadata":{"id":"-JVBekCN69cm","executionInfo":{"status":"ok","timestamp":1657302427123,"user_tz":420,"elapsed":132,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def show_maps(desired_class, num_maps):\n","    '''\n","    goes through the first 10,000 test images and generates CAMs \n","    for the first `num_maps`(int) of the `desired_class`(int)\n","    '''\n","\n","    counter = 0\n","\n","    if desired_class > 10:\n","        print(\"please choose a class less than 10\")\n","\n","    # go through the first 10000 images\n","    for i in range(0,10000):\n","        # break if we already displayed the specified number of maps\n","        if counter == num_maps:\n","            break\n","\n","        # images that match the class will be shown\n","        if np.argmax(results[i]) == desired_class:\n","            counter += 1\n","            show_cam(i)"],"metadata":{"id":"AwqA9buz7EW-","executionInfo":{"status":"ok","timestamp":1657302708287,"user_tz":420,"elapsed":123,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["##Display the CAM on a num_maps for a given class"],"metadata":{"id":"rtQdwoSG7UDy"}},{"cell_type":"code","source":["show_maps(desired_class=4, num_maps=2)\n","show_cam(888)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"Iv6fvrhd7pv-","executionInfo":{"status":"ok","timestamp":1657302900942,"user_tz":420,"elapsed":235,"user":{"displayName":"Otavio Pailo","userId":"08902513118504543900"}},"outputId":"3e2779da-3f9f-4658-b0a9-6a16f91ed383"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class = 5, Probabilty = 0.10273304\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}